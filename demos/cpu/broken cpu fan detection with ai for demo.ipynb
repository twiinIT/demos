{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91919529-aef8-4ced-99ea-8cdd3823e360",
   "metadata": {},
   "source": [
    "# Diagnostic de panne par simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8355b0-b83e-483d-8330-87a7cae6145a",
   "metadata": {},
   "source": [
    "We have computers and we want to know whether their cpu is broken or not.   \n",
    "To be able to know that we use the model of the digital twin to create a model of the cpu.   \n",
    "The digital twin is a way to modelize something material with a program and visualize it on the computer.  \n",
    "This model allows us to create a lot of data that we will use to train an artificial intelligence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f5abcf-cc70-41e2-929e-4d54f72e09d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import packages and set seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b144b9a0-6eae-417c-ab10-b740cb6b829e",
   "metadata": {},
   "source": [
    "To do so we need some packages:   \n",
    "- numpy\n",
    "- pandas to generate and manipulate dataframe\n",
    "- plotly.graph_objects to generate interactive graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5747fd-157c-41f8-99db-99aaa4b46e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f309ffc4-66a0-48d5-9946-989d888cdc0f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e782e610-d02a-4bdd-b809-986102f8779c",
   "metadata": {},
   "source": [
    "To create our datasets we used two digital twins of a cpu made up of a fan, a cpu, a heat exchanger and a controler. The first is working without issue, the second has a broken fan and can't cool the cpu.      The simulation is a usage of 100% for 20 seconds and then 0% for 10 seconds. We take the temperature of the cpu after those 30 seconds.   \n",
    "\n",
    "We then run each digital twins for one thousand air temperature points (with the same distance between two adjacent points) from 0 to 30Â°C, for a total of two thousand cases. We then choose randomly 200 samples of the broken twin and 800 from the one working.   \n",
    "To avoid giving the exact same data in the training and testing sets we won't use the same number of points when running the digital twins: for the test set we will make one thousand and one. We then get the two thousand first cases (one thousand broken and the others working) to create our test set.   \n",
    "The data given in the dataset impact the way our neural network learns. Try to change the dataset: number, pourcentage of each class...   \n",
    "\n",
    "The data in our datasets are: the temperature of the air, the temperature of the cpu and the tension that should be used to make the fan spin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e093e808-93d3-4921-9b35-258a9777cb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv(f\"./data/dataset_999_cases_20_percent_broken.csv\")\n",
    "testset=pd.read_csv(f\"./data/test_set_1000_cases_20_percent_broken.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e949bfac-a286-45df-bb3f-6f6dd65a5cd5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Clear and create datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7473a0fd-8f3a-470b-b9f3-3945f1ac9a2d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### We create the training sets: Xtrain (the data that the neural network will use to learn and determine how to predict a class when we give it data) and ytrain (the classes of the data).   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c1e43c-15a6-466e-9b19-43b78c05a656",
   "metadata": {},
   "source": [
    "Working contains the classes so we drop it for Xtrain, and we keep it for ytrain while dropping all others columns.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79af3887-ed33-4150-bfb5-5af78add7d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = dataset.drop(\"working\", axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a19c66-bbb2-47d7-b568-5f0abd148d1f",
   "metadata": {},
   "source": [
    "We centralize the values of Xtrain by columns and keep the values of its mean and its standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19eaa7b-481c-449b-9072-54fbb6732d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xmean = Xtrain.mean()\n",
    "Xstd = Xtrain.std()\n",
    "Xtrain = (Xtrain-Xmean)/Xstd\n",
    "Xtrain = Xtrain.fillna(0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feacf66d-fbba-49ab-aa82-400d76d488f5",
   "metadata": {},
   "source": [
    "We create ytrain that contains the class of each case: we drop every columns other than Working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ae2f8a-15db-428b-827b-fdcb10db47a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = dataset.drop([\"T_cpu\", \"fan.T_air\", \"fan.tension\"], axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cf6bf7-3f99-4004-a033-1543da862eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We then make numpy array from Xtrain and ytrain to be able to use them later.\n",
    "Xtrain = Xtrain.to_numpy()\n",
    "ytrain = ytrain.to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0611817e-7cdc-4549-ae26-a602c1bdf29d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### We create the test sets: Xtest (the data that the neural network will use to predict a class) and ytest (the classes of the test data we want to determine).   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2a29eb-c252-4eee-b2d1-4b91b246f819",
   "metadata": {},
   "source": [
    "We drop the columns the same way we did for Xtrain and ytrain.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030547cb-863a-46e9-ad3c-1405f260b9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = testset.drop(\"working\", axis=\"columns\")\n",
    "ytest = testset.drop([\"T_cpu\", \"fan.T_air\", \"fan.tension\"], axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6734d4ef-e4c6-4b94-86c2-424d816b8cb7",
   "metadata": {},
   "source": [
    "We also centralize the values of Xtest with the mean and standard deviation of **Xtrain**, not Xtest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9e2bc3-c9e5-4ccb-8e6b-fb0bb1b990fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = (Xtest - Xmean) / Xstd\n",
    "Xtest = Xtest.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbc952d-abab-42bb-a384-13ca2328e3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We then make numpy array from Xtest and ytest.\n",
    "Xtest = Xtest.to_numpy()\n",
    "ytest = ytest.to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7750f9-c62f-4ce6-8320-e06db67c5f3c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create and train the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6756b5-3a9e-4529-b5df-066c90c1c114",
   "metadata": {},
   "source": [
    "Here we create our neural network using the MLPClassifier function from sklearn.   \n",
    "The solver is the solver for weight optimization. There are 3 choices: lbfgs, an optimizer in the family of quasi-Newton methods, sgd: stochastic gradient descent and adam a stochastic gradient-based optimizer.   \n",
    "random_state is here to control the random number generator used and know if our neuralNetwork really improved after we modified it. It could have been an unlucky then lucky random number generator. You can try 99 to see a huge difference.   \n",
    "The lenght of the hidden_layer parameter is the number of layer of neuron and the ith number is the number of the ith layer.   \n",
    "verbose=False is to avoid seeing the result of each iteration: if True it gives the loss of each iteration.   \n",
    "shuffle=True is to shuffle or not the data at each iteration.   \n",
    "max_iter: the maximum number of iteration if the neural network doesn't stop before (default: 200, try putting 300 to see it stop by itself)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740a8ecb-e3ed-47bd-b028-f9c4c73876d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuralNetwork = MLPClassifier(solver='sgd', random_state=1, hidden_layer_sizes=(10, 10, 10, 10), verbose=False, shuffle=True, max_iter=200)\n",
    "neuralNetwork.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a539beb-2189-4b1c-a02a-51c4763cf1a0",
   "metadata": {},
   "source": [
    "## Data study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c5f34c-c24a-47e9-b95d-4e2fb1c5c575",
   "metadata": {},
   "source": [
    "We will predict the class of the data from Xtest and collect the probabilities for each class to study them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c467ab-95f4-4671-bf4d-52d27794fda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction=neuralNetwork.predict(Xtest) #the classes\n",
    "y_prediction_probas=neuralNetwork.predict_proba(Xtest) #the probabilities for each classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10d6740-0d15-4644-91b9-d52b8a78f00b",
   "metadata": {},
   "source": [
    "y_prediction_probas is the liste of probabilities for each line in Xtest. Here it has 2 columns, each for  class, representing their probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa6544c-05e0-46fe-9404-1025cd849496",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction_probas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4bac62-4a6b-4e81-98ca-1acefed91bd2",
   "metadata": {},
   "source": [
    "Creation of mask allowing us to check the class of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157530de-9d59-40e2-9cbc-93df47c456b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "maskNoProblem=testset[\"working\"]==True\n",
    "maskBroken=testset[\"working\"]==False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035a1a8f-dea5-4994-923d-7a87c1c2bef0",
   "metadata": {},
   "source": [
    "We check the percentage of right answers of our model: one way to check if it works or not. However we do NOT know if for the neural network it has 50.1% or 100% probability to be the class given. We only know which one has the higher probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df552dd1-23b4-49d4-a6cc-7f1535845770",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\"Percentage of right guesses:\", neuralNetwork.score(Xtest, ytest)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e972f15-cdbd-4411-ab2f-be4d39d07f55",
   "metadata": {},
   "source": [
    "That is why we create and use a function to display various statistics: median, mean, standard deviation, minimum and maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b5fae8-553f-4518-99de-738b9bf67775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stats(arr):\n",
    "    return dict(median=np.median(arr)*100, mean=np.mean(arr)*100, std=np.std(arr)*100, min=np.min(arr)*100, max=np.max(arr)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c84156-94dd-4e29-9122-b76a89e4402d",
   "metadata": {},
   "source": [
    "Stats of dysfunctional cpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf57b6c4-41ec-4f80-ab5e-6301d73caaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_stats(y_prediction_probas[maskBroken][:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef581ed4-558f-4269-b7ff-7809a7a82d68",
   "metadata": {},
   "source": [
    "Stats of working cpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d62a673-0156-42b5-8698-222dd452bfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_stats(y_prediction_probas[maskNoProblem][:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1bb6b0-610e-4eb0-a999-84501d60ba44",
   "metadata": {},
   "source": [
    "We plot probability(Temp) for each type of cpu.   \n",
    "That is the probability given by the neural network to the right class for each point we gave it in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae910e9d-bb6b-4ae3-afa1-6c5f437db0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"Broken\":y_prediction_probas[maskBroken][:,0], \"No problem\":y_prediction_probas[maskNoProblem][:,1],\"Temp\":testset[maskNoProblem][\"fan.T_air\"]})\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df[\"Temp\"], y=df[\"Broken\"], mode='markers', name=\"Broken\"))\n",
    "fig.add_trace(go.Scatter(x=df[\"Temp\"], y=df[\"No problem\"], mode='markers', name=\"No problem\"))\n",
    "fig.layout = go.Layout(\n",
    "        title = {'text': 'Percentage of prediction function of temperature', 'font': {'size': 34}, 'x': 0.5},\n",
    "        width = 1200,\n",
    "        height = 600,\n",
    "        xaxis = {'title': {'text': 'Temperature', 'font': {'size': 20}}, 'gridcolor': '#EBF0F8'},\n",
    "        yaxis = {'title': {'text': 'Percentage of prediction', 'font': {'size': 20}}, 'gridcolor': '#EBF0F8'},\n",
    "        yaxis2 = {'title': {'text': 'weight (kg)', 'font': {'size': 20}}, 'side': \"right\", 'gridcolor': '#EBF0F8', \"overlaying\": \"y\"},\n",
    "        plot_bgcolor = 'white',\n",
    "        hovermode = 'x',\n",
    "    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ff640d-5a50-453d-9c59-7d23760988d6",
   "metadata": {},
   "source": [
    "Boxplots of probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee1e49d-9fef-4307-9cc6-4118000072a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Box(\n",
    "    y=y_prediction_probas[maskBroken][:,0],\n",
    "    name=\"Broken\",\n",
    "    jitter=0.3,\n",
    "    pointpos=-1.8,\n",
    "    boxpoints='all', # represent all points\n",
    "    marker_color='rgb(255, 0, 0)',\n",
    "    line_color='rgb(255, 0, 0)'\n",
    "))\n",
    "fig.add_trace(go.Box(\n",
    "    y=y_prediction_probas[maskNoProblem][:,1],\n",
    "    name=\"Working\",\n",
    "    jitter=0.3,\n",
    "    pointpos=-1.8,\n",
    "    boxpoints='all', # represent all points\n",
    "    marker_color='rgb(0, 255, 0)',\n",
    "    line_color='rgb(0, 255, 0)'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d6f070-08b4-41c8-a394-df4ee89ab9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentageNumbers(first, second, classes=[True, False], masks=[maskBroken, maskNoProblem]):\n",
    "    \n",
    "    firstGroup=[0]*len(classes)\n",
    "    secondGroup=[0]*len(classes)\n",
    "    lowGroup=[0]*len(classes)\n",
    "    wrongGroup=[0]*len(classes)\n",
    "    numberPerClass=[k.value_counts()[True] for k in masks]\n",
    "    print(numberPerClass)\n",
    "    \n",
    "    for k in range(len(masks)):\n",
    "        for i in range(len(y_prediction[masks[k]])):\n",
    "            #print(ytest[masks[k]][i], y_prediction[masks[k]][i], y_prediction_probas[masks[k]][i][k])\n",
    "            if ytest[masks[k]][i]!=y_prediction[masks[k]][i]:\n",
    "                wrongGroup[k]+=1\n",
    "            elif y_prediction_probas[masks[k]][i][k]>first:\n",
    "                firstGroup[k]+=1\n",
    "            elif y_prediction_probas[masks[k]][i][k]>second:\n",
    "                secondGroup[k]+=1\n",
    "            else:\n",
    "                lowGroup[k]+=1\n",
    "    return np.array(firstGroup)/np.array(numberPerClass), np.array(secondGroup)/np.array(numberPerClass), np.array(lowGroup)/np.array(numberPerClass), np.array(wrongGroup)/np.array(numberPerClass)\n",
    "\n",
    "percentageNumbers(0.95,0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e61ee78-c40e-4c66-a7c2-ec7e2a8deee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=percentageNumbers(0.95,0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc0ff1d-341b-4451-adb4-4c399ed5dfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[\n",
    "    go.Bar(name='95<', x=[\"Broken\", \"No problem\"], y=test[0], text=test[0]),\n",
    "    go.Bar(name='90< <95', x=[\"Broken\", \"No problem\"], y=test[1], text=test[1]),\n",
    "    go.Bar(name='<90', x=[\"Broken\", \"No problem\"], y=test[2], text=test[2]),\n",
    "    go.Bar(name='Wrong', x=[\"Broken\", \"No problem\"], y=test[3], text=test[3])\n",
    "])\n",
    "# Change the bar mode\n",
    "fig.update_layout(barmode='stack')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9e7906-af6a-45a8-9d46-85b32bbd4587",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(\n",
    "    x=y_prediction_probas[:,1],\n",
    "    histnorm='percent',\n",
    "    xbins=dict(\n",
    "        start=0,\n",
    "        end=1.0,\n",
    "        size=0.01\n",
    "    ),\n",
    "    opacity=0.7\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text='Precision of the prediction',\n",
    "    xaxis_title_text='Precision',\n",
    "    yaxis_title_text='Percentage of prediction',\n",
    "    bargap=0.2,\n",
    "    bargroupgap=0.1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
